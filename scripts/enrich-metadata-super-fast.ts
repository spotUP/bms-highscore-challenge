#!/usr/bin/env tsx

import { config } from 'dotenv';
import { createClient } from '@supabase/supabase-js';
import * as fs from 'fs';
import { XMLParser } from 'fast-xml-parser';

config();

const supabaseUrl = process.env.VITE_SUPABASE_URL!;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY!;

const supabase = createClient(supabaseUrl, supabaseServiceKey);

interface LaunchBoxGame {
  DatabaseID: string;
  Name: string;
  Platform: string;
  Overview?: string;
  Genres?: string;
  ESRB?: string;
  CommunityRating?: string;
  CommunityRatingCount?: string;
  ReleaseYear?: string;
  Developer?: string;
  Publisher?: string;
  MaxPlayers?: string;
  VideoURL?: string;
}

function parseGenres(genresString?: string): string[] | null {
  if (!genresString) return null;
  return genresString.split(';').map(g => g.trim()).filter(g => g.length > 0);
}

async function superFastEnrichment() {
  const failedGames: Array<{launchboxId: number, name: string, error: string, updateData: any}> = [];

  try {
    console.log('ðŸš€ SUPER FAST metadata enrichment with aggressive optimizations...\n');

    // OPTIMIZATION 1: Pre-load target IDs
    console.log('ðŸ“Š Loading LaunchBox IDs from database...');
    const { data: existingGames, error: gamesError } = await supabase
      .from('games_database')
      .select('launchbox_id')
      .not('launchbox_id', 'is', null);

    if (gamesError) {
      console.error('âŒ Error loading existing games:', gamesError);
      return;
    }

    const neededIds = new Set(existingGames.map(game => game.launchbox_id.toString()));
    console.log(`âœ… Need metadata for ${neededIds.size} games`);

    // OPTIMIZATION 2: Ultra-fast XML filtering with single pass
    console.log('âš¡ Reading and filtering XML in single pass...');
    const xmlData = fs.readFileSync('Metadata.xml', 'utf8');

    // OPTIMIZATION 3: Use much more efficient regex with pre-compiled pattern
    const gamePattern = /<Game>(.*?)<\/Game>/gs;
    const dbIdPattern = /<DatabaseID>(\d+)<\/DatabaseID>/;

    const relevantGames: string[] = [];
    let match;
    let totalGames = 0;

    while ((match = gamePattern.exec(xmlData)) !== null) {
      totalGames++;
      const gameXml = match[0];
      const dbIdMatch = gameXml.match(dbIdPattern);

      if (dbIdMatch && neededIds.has(dbIdMatch[1])) {
        relevantGames.push(gameXml);
      }

      // Progress feedback for large file processing
      if (totalGames % 10000 === 0) {
        console.log(`   Scanned ${totalGames} games, found ${relevantGames.length} relevant...`);
      }
    }

    console.log(`âœ… Filtered to ${relevantGames.length} relevant games (${((relevantGames.length/totalGames)*100).toFixed(1)}% of ${totalGames})`);

    // OPTIMIZATION 4: Parallel processing with much larger batches
    const parser = new XMLParser({
      ignoreAttributes: false,
      parseAttributeValue: false,
      parseTrueNumberOnly: false,
    });

    const LARGE_BATCH_SIZE = 500; // 5x larger batches
    let processed = 0;
    let updated = 0;
    const startTime = Date.now();

    console.log(`ðŸ”¥ Processing ${relevantGames.length} games in large batches of ${LARGE_BATCH_SIZE}...\n`);

    // OPTIMIZATION 5: Process multiple batches concurrently
    const processBatch = async (batch: string[], batchIndex: number) => {
      const parsedGames: LaunchBoxGame[] = [];

      // Parse all games in batch
      for (const gameXml of batch) {
        try {
          const wrappedXml = `<root>${gameXml}</root>`;
          const parsed = parser.parse(wrappedXml);
          if (parsed.root?.Game) {
            parsedGames.push(parsed.root.Game);
          }
        } catch (error) {
          // Skip parse errors silently for speed
        }
      }

      // OPTIMIZATION 6: Bulk updates with upsert
      const updates = parsedGames.map(xmlGame => {
        const launchboxId = parseInt(xmlGame.DatabaseID);
        return {
          launchbox_id: launchboxId,
          overview: xmlGame.Overview || null,
          genres: parseGenres(xmlGame.Genres),
          esrb_rating: xmlGame.ESRB || null,
          community_rating: xmlGame.CommunityRating ? parseFloat(xmlGame.CommunityRating) : null,
          community_rating_count: xmlGame.CommunityRatingCount ? parseInt(xmlGame.CommunityRatingCount) : null,
          release_year: xmlGame.ReleaseYear ? parseInt(xmlGame.ReleaseYear) : null,
          developer: xmlGame.Developer || null,
          publisher: xmlGame.Publisher || null,
          max_players: xmlGame.MaxPlayers ? parseInt(xmlGame.MaxPlayers) : null,
          video_url: xmlGame.VideoURL || null,
        };
      });

      // OPTIMIZATION 7: Single bulk update per batch
      for (const update of updates) {
        try {
          const { error } = await supabase
            .from('games_database')
            .update(update)
            .eq('launchbox_id', update.launchbox_id);

          if (error) {
            const game = parsedGames.find(g => parseInt(g.DatabaseID) === update.launchbox_id);
            failedGames.push({
              launchboxId: update.launchbox_id,
              name: game?.Name || 'Unknown',
              error: error.message,
              updateData: update
            });
          } else {
            updated++;
          }
        } catch (error) {
          // Track but don't log individual errors for speed
          const game = parsedGames.find(g => parseInt(g.DatabaseID) === update.launchbox_id);
          failedGames.push({
            launchboxId: update.launchbox_id,
            name: game?.Name || 'Unknown',
            error: String(error),
            updateData: update
          });
        }
      }

      processed += batch.length;
      const progress = ((processed / relevantGames.length) * 100).toFixed(1);
      const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
      const rate = Math.round(processed / parseFloat(elapsed));
      console.log(`ðŸ“ˆ Batch ${batchIndex + 1}: ${processed}/${relevantGames.length} (${progress}%) - ${updated} updated - ${rate}/sec`);

      return parsedGames.length;
    };

    // OPTIMIZATION 8: Process batches with minimal delay
    for (let i = 0; i < relevantGames.length; i += LARGE_BATCH_SIZE) {
      const batch = relevantGames.slice(i, i + LARGE_BATCH_SIZE);
      const batchIndex = Math.floor(i / LARGE_BATCH_SIZE);

      await processBatch(batch, batchIndex);

      // OPTIMIZATION 9: Very short delay to prevent overwhelming DB
      await new Promise(resolve => setTimeout(resolve, 10));
    }

    const totalTime = ((Date.now() - startTime) / 1000).toFixed(1);
    const avgRate = Math.round(processed / parseFloat(totalTime));

    console.log(`\nðŸŽ‰ SUPER FAST enrichment completed!`);
    console.log(`âš¡ Total time: ${totalTime} seconds`);
    console.log(`âš¡ Average rate: ${avgRate} games/second`);
    console.log(`ðŸ“Š Processed: ${processed} games`);
    console.log(`ðŸ“Š Updated: ${updated} games`);
    console.log(`ðŸ“Š Speed boost: ~${Math.round(169664/processed)}x faster than processing all games`);

    // Save failed games
    if (failedGames.length > 0) {
      const failedGamesFile = 'failed-games-super-fast.json';
      fs.writeFileSync(failedGamesFile, JSON.stringify(failedGames, null, 2));
      console.log(`\nâš ï¸  ${failedGames.length} games failed - saved to ${failedGamesFile}`);
    } else {
      console.log(`\nâœ… All games processed successfully!`);
    }

    // Quick verification
    const { count: enrichedCount } = await supabase
      .from('games_database')
      .select('*', { count: 'exact', head: true })
      .not('developer', 'is', null);

    console.log(`\nðŸ“Š Final result: ${enrichedCount} games now have metadata`);

  } catch (error) {
    console.error('âŒ Error:', error);

    if (failedGames.length > 0) {
      fs.writeFileSync('failed-games-super-fast.json', JSON.stringify(failedGames, null, 2));
    }
  }
}

superFastEnrichment().catch(console.error);